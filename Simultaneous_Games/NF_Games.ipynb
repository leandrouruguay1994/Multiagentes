{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from itertools import product\n",
    "from games.mp import MP\n",
    "from games.rps import RPS\n",
    "from games.blotto import Blotto\n",
    "\n",
    "from agents.fictitiousplay import FictitiousPlay\n",
    "from agents.regretmatching import RegretMatching\n",
    "from agents.random_agent import RandomAgent\n",
    "\n",
    "import os\n",
    "os.environ['WANDB_SILENT'] = \"true\"\n",
    "os.environ['WANDB_START_METHOD'] = \"thread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de experimentos\n",
    "CONFIGS = [\n",
    "    {\n",
    "        'game': 'MP',\n",
    "        'game_params': {},\n",
    "        'train_config': {'episodes': 1000, 'iterations': 10},\n",
    "        'eval_config': {'episodes': 500},\n",
    "        'agents': {\n",
    "            'agent_0': {'type': 'fictitious_play', 'config': {'initial': None, 'seed': 42}},\n",
    "            'agent_1': {'type': 'regret_matching', 'config': {'initial': None, 'seed': 42}}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'game': 'RPS',\n",
    "        'game_params': {},\n",
    "        'train_config': {'episodes': 1000, 'iterations': 10},\n",
    "        'eval_config': {'episodes': 500},\n",
    "        'agents': {\n",
    "            'agent_0': {'type': 'fictitious_play', 'config': {'initial': None, 'seed': 42}},\n",
    "            'agent_1': {'type': 'random', 'config': {'initial': None, 'seed': 42}}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'game': 'Blotto',\n",
    "        'game_params': {'S': 5, 'N': 2},\n",
    "        'train_config': {'episodes': 500, 'iterations': 20},\n",
    "        'eval_config': {'episodes': 200},\n",
    "        'agents': {\n",
    "            'agent_0': {'type': 'regret_matching', 'config': {'initial': None, 'seed': 42}},\n",
    "            'agent_1': {'type': 'fictitious_play', 'config': {'initial': None, 'seed': 42}}\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_wandb(config):\n",
    "    \"\"\"Configura Weights & Biases para tracking\"\"\"\n",
    "    wandb.init(\n",
    "        project=\"normal_form_games\",\n",
    "        config={\n",
    "            'game': config['game'],\n",
    "            'game_params': config['game_params'],\n",
    "            'train_episodes': config['train_config']['episodes'],\n",
    "            'train_iterations': config['train_config']['iterations'],\n",
    "            'agent_types': {k: v['type'] for k, v in config['agents'].items()}\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game(game_name, game_params):\n",
    "    \"\"\"Factory para crear juegos\"\"\"\n",
    "    if game_name == 'MP':\n",
    "        return MP()\n",
    "    elif game_name == 'RPS':\n",
    "        return RPS()\n",
    "    elif game_name == 'Blotto':\n",
    "        return Blotto(**game_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Juego no soportado: {game_name}\")\n",
    "\n",
    "def create_agent(agent_type, game, agent_id, config):\n",
    "    \"\"\"Factory para crear agentes\"\"\"\n",
    "    if agent_type == 'fictitious_play':\n",
    "        return FictitiousPlay(game, agent_id, **config)\n",
    "    elif agent_type == 'regret_matching':\n",
    "        return RegretMatching(game, agent_id, **config)\n",
    "    elif agent_type == 'random':\n",
    "        return RandomAgent(game, agent_id, **config)\n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de agente no soportado: {agent_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28288547",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def play_episode(game, agents, verbose=False):\n",
    "    \"\"\"Ejecuta un episodio del juego\"\"\"\n",
    "    game.reset()\n",
    "    actions = {agent_id: agents[agent_id].action() for agent_id in game.agents}\n",
    "    _, rewards, _, _, _ = game.step(actions)\n",
    "    \n",
    "    if verbose:\n",
    "        game.render()\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "def train(game, agents, train_config):\n",
    "    \"\"\"Entrena agentes en el juego\"\"\"\n",
    "    stats = {\n",
    "        'rewards': {agent_id: [] for agent_id in game.agents},\n",
    "        'policies': {agent_id: [] for agent_id in game.agents}\n",
    "    }\n",
    "    \n",
    "    total_episodes = train_config['episodes'] * train_config['iterations']\n",
    "    \n",
    "    with tqdm(total=total_episodes, desc=\"Training\") as pbar:\n",
    "        for _ in range(train_config['iterations']):\n",
    "            iteration_rewards = {agent_id: 0 for agent_id in game.agents}\n",
    "            \n",
    "            for _ in range(train_config['episodes']):\n",
    "                rewards = play_episode(game, agents)\n",
    "                \n",
    "                for agent_id in game.agents:\n",
    "                    iteration_rewards[agent_id] += rewards[agent_id]\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            # Guardar estadísticas\n",
    "            for agent_id in game.agents:\n",
    "                avg_reward = iteration_rewards[agent_id] / train_config['episodes']\n",
    "                stats['rewards'][agent_id].append(avg_reward)\n",
    "                stats['policies'][agent_id].append(agents[agent_id].policy())\n",
    "                \n",
    "                if wandb.run:\n",
    "                    wandb.log({\n",
    "                        f\"train/{agent_id}_avg_reward\": avg_reward,\n",
    "                        \"episode\": wandb.run.step\n",
    "                    })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def evaluate(game, agents, eval_config, against_fixed=None):\n",
    "    \"\"\"Evalúa agentes contra otros o políticas fijas\"\"\"\n",
    "    stats = {\n",
    "        'rewards': {agent_id: [] for agent_id in game.agents},\n",
    "        'policies': {agent_id: agents[agent_id].policy() for agent_id in game.agents}\n",
    "    }\n",
    "    \n",
    "    # Configurar oponentes\n",
    "    if against_fixed:\n",
    "        eval_agents = {}\n",
    "        for agent_id in game.agents:\n",
    "            if agent_id in against_fixed:\n",
    "                eval_agents[agent_id] = against_fixed[agent_id]\n",
    "            else:\n",
    "                eval_agents[agent_id] = agents[agent_id]\n",
    "    else:\n",
    "        eval_agents = agents\n",
    "    \n",
    "    with tqdm(total=eval_config['episodes'], desc=\"Evaluation\") as pbar:\n",
    "        for _ in range(eval_config['episodes']):\n",
    "            rewards = play_episode(game, eval_agents)\n",
    "            \n",
    "            for agent_id in game.agents:\n",
    "                stats['rewards'][agent_id].append(rewards[agent_id])\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Calcular promedios\n",
    "    for agent_id in game.agents:\n",
    "        avg_reward = np.mean(stats['rewards'][agent_id])\n",
    "        stats['rewards'][agent_id] = avg_reward\n",
    "        \n",
    "        if wandb.run:\n",
    "            wandb.log({\n",
    "                f\"eval/{agent_id}_avg_reward\": avg_reward,\n",
    "                \"episode\": wandb.run.step\n",
    "            })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def plot_results(train_stats, eval_stats, agents, game_name):\n",
    "    \"\"\"Visualiza resultados de entrenamiento y evaluación\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Gráfico 1: Progreso de entrenamiento\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for agent_id in train_stats['rewards']:\n",
    "        plt.plot(train_stats['rewards'][agent_id], \n",
    "                label=f\"{agent_id} ({type(agents[agent_id]).__name__})\")\n",
    "    plt.title(f\"Training Progress\\n{game_name}\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Average Reward\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gráfico 2: Políticas aprendidas\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for agent_id in train_stats['policies']:\n",
    "        final_policy = train_stats['policies'][agent_id][-1]\n",
    "        plt.bar(range(len(final_policy)), final_policy, \n",
    "               alpha=0.6, label=f\"{agent_id} Policy\")\n",
    "    plt.title(\"Final Policies\")\n",
    "    plt.xlabel(\"Action\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gráfico 3: Recompensas de evaluación\n",
    "    plt.subplot(1, 3, 3)\n",
    "    agent_ids = list(eval_stats['rewards'].keys())\n",
    "    rewards = [eval_stats['rewards'][agent_id] for agent_id in agent_ids]\n",
    "    plt.bar(agent_ids, rewards, alpha=0.6)\n",
    "    plt.title(\"Evaluation Rewards\")\n",
    "    plt.ylabel(\"Average Reward\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar en W&B\n",
    "    if wandb.run:\n",
    "        wandb.log({\"results\": plt})\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def run_experiment(config):\n",
    "    \"\"\"Ejecuta un experimento completo\"\"\"\n",
    "    print(f\"\\n=== Running Experiment: {config['game']} ===\")\n",
    "    print(f\"Agents: { {k: v['type'] for k, v in config['agents'].items()} }\")\n",
    "    \n",
    "    # Setup W&B\n",
    "    setup_wandb(config)\n",
    "    \n",
    "    # Crear juego y agentes\n",
    "    game = create_game(config['game'], config['game_params'])\n",
    "    agents = {\n",
    "        agent_id: create_agent(agent_config['type'], game, agent_id, agent_config['config'])\n",
    "        for agent_id, agent_config in config['agents'].items()\n",
    "    }\n",
    "    \n",
    "    # Fase de entrenamiento\n",
    "    train_stats = train(game, agents, config['train_config'])\n",
    "    \n",
    "    # Fase de evaluación\n",
    "    eval_stats = evaluate(game, agents, config['eval_config'])\n",
    "    \n",
    "    # Visualización\n",
    "    plot_results(train_stats, eval_stats, agents, config['game'])\n",
    "    \n",
    "    # Finalizar W&B\n",
    "    wandb.finish()\n",
    "    \n",
    "    return train_stats, eval_stats\n",
    "\n",
    "# Ejecutar todos los experimentos\n",
    "if __name__ == \"__main__\":\n",
    "    # Iniciar sesión en W&B (solo una vez)\n",
    "    wandb.login()\n",
    "    \n",
    "    # Ejecutar configuraciones\n",
    "    for config in CONFIGS:\n",
    "        train_stats, eval_stats = run_experiment(config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
